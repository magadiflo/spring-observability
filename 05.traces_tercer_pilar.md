# Traces - Tercer pilar de la observabilidad

La observabilidad moderna se apoya en `tres pilares` fundamentales: `m√©tricas`, `logs` y `traces`.
En esta secci√≥n nos enfocaremos en el tercero: los `traces`, tambi√©n llamados `distributed tracing`.

### üìä Repaso r√°pido: m√©tricas, logs y traces

| Pilar    | ¬øQu√© mide?                        | ¬øCu√°ndo usar?                            | Ejemplo                                                  |
|----------|-----------------------------------|------------------------------------------|----------------------------------------------------------|
| M√©tricas | Valores num√©ricos agregados       | Monitoreo continuo, alertas              | `orders_total = 150`                                     |
| Logs     | Eventos espec√≠ficos en texto      | Debugging, auditor√≠a                     | `Orden 123 creada exitosamente`                          |
| Traces   | Flujo de requests entre servicios | An√°lisis de latencia, cuellos de botella | `POST /orders: 290ms` `(API‚ÜíOrder‚ÜíPayment‚ÜíNotification)` |

- `M√©tricas` ‚Üí datos num√©ricos agregados que muestran el estado del sistema en el tiempo (ej. latencia promedio de
  requests, uso de CPU, throughput).
- `Logs` ‚Üí registros detallados y estructurados de eventos individuales, √∫tiles para depuraci√≥n y auditor√≠a
  (ej. `Order 123 created successfully`).
- `Traces` ‚Üí narran el recorrido de una petici√≥n a trav√©s del sistema, mostrando c√≥mo se propaga entre servicios o
  componentes y cu√°nto tarda cada parte.

> üëâ Mientras que `m√©tricas` responden al `qu√© est√° pasando` y `logs` al `qu√© ocurri√≥` exactamente, los `traces`
> responden al `c√≥mo fluye una petici√≥n`.

### üîë Conceptos clave en tracing

- `Trace` ‚Üí Representa el flujo completo de una petici√≥n de inicio a fin (por ejemplo: crear un pedido).
- `Span` ‚Üí Unidad de trabajo dentro de un trace (ej. validar datos, persistir pedido, llamar a servicio de pago).
  Cada span tiene inicio, fin y duraci√≥n.
- `traceId` ‚Üí Identificador √∫nico compartido por todos los spans de un mismo trace.
- `spanId` ‚Üí Identificador √∫nico de cada span.
- `parentId` ‚Üí Relaci√≥n jer√°rquica: indica qu√© span origin√≥ al actual.

### üîó Relaci√≥n con un request real

Cuando un request entra al sistema (por ejemplo, `POST /orders`):

1. Se crea un `traceId` que identifica toda la operaci√≥n.
2. El request inicial genera un `root span`.
3. Cada operaci√≥n interna (validaci√≥n, persistencia, llamadas externas) se representa como child spans.
4. Todos los `spans` se encadenan gracias al campo `parentId`, que apunta al `spanId` de su padre. Con esta relaci√≥n se
   puede reconstruir el flujo completo de la petici√≥n.

Un trace t√≠pico podr√≠a representarse as√≠:

````
traceId: abc123def456    # √önico para todo el request
‚îú‚îÄ‚îÄ spanId: span-001     # Root span (API Gateway)
‚îÇ   ‚îî‚îÄ‚îÄ parentId: null
‚îú‚îÄ‚îÄ spanId: span-002     # Child span (Order Service)
‚îÇ   ‚îî‚îÄ‚îÄ parentId: span-001
‚îî‚îÄ‚îÄ spanId: span-003     # Child span (Payment Service)
    ‚îî‚îÄ‚îÄ parentId: span-001 
````

En este ejemplo:

- Todos los `spans` comparten el mismo `traceId`.
- El `span-001` es el `root span` que inicia la petici√≥n.
- Los spans `002` y `003` son hijos que representan operaciones internas, pero mantienen la relaci√≥n jer√°rquica gracias
  al `parentId`.

As√≠, un trace act√∫a como un √°rbol de ejecuci√≥n que permite entender el recorrido completo de la petici√≥n y detectar
cuellos de botella.
---

# Fase 1: Infraestructura y Configuraci√≥n Base

## üöÄ Paso 1 - Agregar `Tempo` al `Docker Compose`

Para almacenar y consultar trazas utilizaremos `Grafana Tempo`. Este servicio se ejecutar√° en contenedores Docker y
recibir√° los traces exportados por nuestra aplicaci√≥n `Spring Boot`.

### Servicio Tempo en `compose.yml`

````yml
services:
  s-tempo:
    image: grafana/tempo:2.8.2
    container_name: c-tempo
    restart: unless-stopped
    ports:
      - "4318:4318"   # OTLP HTTP receiver (usado por Spring Boot)
      - "3200:3200"   # Tempo UI (opcional, √∫til para debug sin Grafana)
    volumes:
      - ./tempo/tempo.yml:/etc/tempo/tempo.yml
    command: [ '-config.file=/etc/tempo/tempo.yml' ]
    networks:
      - observability-net
````

- Puerto `4318`: Recibe traces en formato OTLP HTTP (protocolo REST, m√°s compatible).
- Puerto `3200`: Interface web de Tempo para debug y consultas directas.

### Archivo de configuraci√≥n `tempo/tempo.yml`

````yml
server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        http:
          endpoint: 0.0.0.0:4318

storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo/traces
    wal:
      path: /tmp/tempo/wal

compactor:
  compaction:
    block_retention: 1h

usage_report:
  reporting_enabled: false
````

- `Tempo` quedar√° escuchando en el puerto `4318 (HTTP)` para recibir traces v√≠a `OTLP`, que es el
  est√°ndar de `OpenTelemetry`.
- La UI m√≠nima estar√° disponible en `http://localhost:3200`.
- Los `traces` se almacenar√°n localmente bajo `/tmp/tempo`.
- `server.http_listen_port: 3200` ‚Üí puerto donde `Tempo` expone su `API HTTP` para consultas.
- `receivers.otlp`:
    - `http` endpoint `0.0.0.0:4318`: Acepta traces v√≠a protocolo HTTP desde cualquier IP.
    - `OTLP` (OpenTelemetry Protocol): Est√°ndar industria para env√≠o de telemetr√≠a.
- `storage.trace`:
    - `backend: local`: Almacena traces en disco local (ideal para desarrollo).
    - `path: /tmp/tempo/traces`: Directorio donde se guardan los traces procesados.
    - `wal path`: Write Ahead Log - garantiza durabilidad antes de procesar.
- `block_retention: 1h`: Mantiene traces por 1 hora antes de eliminarlos (ajustable seg√∫n necesidades).
- `reporting_enabled: false`: Desactiva env√≠o de m√©tricas de uso a Grafana Labs (privacidad).

### Levantar la infraestructura

Levantamos nuestros servicios ejecutando el siguiente comando de docker compose.

````bash
D:\programming\spring\15.martin_diaz\spring-observability (main -> origin)
$ docker compose -f ./docker/compose.yml up -d
````

Verificamos que todos los contenedores est√©n levantados.

````bash
$ docker container ls -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED          STATUS          PORTS                                                                                      NAMES
8aafeb2fd995   grafana/tempo:2.8.2      "/tempo -config.file‚Ä¶"   20 seconds ago   Up 20 seconds   0.0.0.0:3200->3200/tcp, [::]:3200->3200/tcp, 0.0.0.0:4318->4318/tcp, [::]:4318->4318/tcp   c-tempo
48e4654f4054   grafana/promtail:3.5.5   "/usr/bin/promtail -‚Ä¶"   20 seconds ago   Up 21 seconds                                                                                              c-promtail
2a4d6205a3e5   prom/prometheus:v3.5.0   "/bin/prometheus --c‚Ä¶"   20 seconds ago   Up 20 seconds   0.0.0.0:9090->9090/tcp, [::]:9090->9090/tcp                                                c-prometheus
d993aa81f056   grafana/loki:3.5.5       "/usr/bin/loki -conf‚Ä¶"   21 seconds ago   Up 20 seconds   0.0.0.0:3100->3100/tcp, [::]:3100->3100/tcp                                                c-loki
dc84a26479c9   grafana/grafana:12.1.1   "/run.sh"                21 seconds ago   Up 20 seconds   0.0.0.0:3000->3000/tcp, [::]:3000->3000/tcp                                                c-grafana
````

### üê≥ Nota: Acceso al contenedor de Tempo

Normalmente, si queremos ingresar a un contenedor para inspeccionarlo, usar√≠amos un `shell` como:

````bash
docker container exec -it <container_name> /bin/sh
# o
docker container exec -it <container_name> /bin/bash 
````

Sin embargo, la imagen oficial de `Grafana Tempo` est√° construida de forma minimalista `(distroless)`, lo que significa
que no incluye shell (`/bin/sh` o `/bin/bash`).

Por ello, si intentamos acceder con uno de los comandos anteriores el resultado ser√° un error como este:

````bash
$ docker container exec -it c-tempo /bin/sh
OCI runtime exec failed: exec failed: unable to start container process: exec: "/bin/sh": stat /bin/sh: no such file or directory: unknown
````

#### ‚úÖ ¬øC√≥mo inspeccionar el contenedor en este caso?

Aunque no tengamos shell dentro del contenedor, s√≠ podemos ejecutar comandos directamente con `docker container exec`.
Por ejemplo:

- Ver el archivo de configuraci√≥n montado:
    ````bash
    $ docker container exec -it c-tempo cat /etc/tempo/tempo.yml
    server:
      http_listen_port: 3200
    
    distributor:
      receivers:
        otlp:
          protocols:
            http:
              endpoint: 0.0.0.0:4318
    
    storage:
      trace:
        backend: local
        local:
          path: /tmp/tempo/traces
        wal:
          path: /tmp/tempo/wal
    
    compactor:
      compaction:
        block_retention: 1h
    
    usage_report:
      reporting_enabled: false
    ````
- Listar la carpeta de configuraci√≥n:
    ````bash
    $ docker container exec -it c-tempo ls -l /etc/tempo
    total 0
    -rwxrwxrwx    1 root     root           414 Sep 17 22:54 tempo.yml
    ````
- Validar el bind mount desde el host:
    ````bash
    $ docker container inspect c-tempo
    [
        {
            "Id": "8aafeb2fd9957a8cb05242e779ca471dd313e69ca97a215e29f45cac1a18cf5e",
            ...
                ...
            "Mounts": [
                {
                    "Type": "bind",
                    "Source": "D:\\programming\\spring\\15.martin_diaz\\spring-observability\\docker\\tempo\\tempo.yml",
                    "Destination": "/etc/tempo/tempo.yml",
                    "Mode": "rw",
                    "RW": true,
                    "Propagation": "rprivate"
                }
            ],
            ...
        }
    ]
    ````

De esta manera, podemos confirmar que nuestro archivo tempo.yml est√° correctamente montado y en uso, sin necesidad de
acceder con un shell.

## üöÄ Paso 2 - Configurar Micrometer Tracing en Spring Boot

### üîé Introducci√≥n te√≥rica

Para que nuestra aplicaci√≥n pueda `generar y exportar traces hacia Tempo`, necesitamos instrumentarla con librer√≠as
que:

1. `Micrometer Tracing`
    - Es la evoluci√≥n de `Spring Cloud Sleuth`.
    - Biblioteca de `abstracci√≥n` para tracing en Spring Boot.
    - Similar a como `SLF4J` abstrae `logging`, `Micrometer` abstrae `tracing`.
    - Te permite cambiar implementaciones sin cambiar c√≥digo.
    - Proporciona una API unificada para generar `traces` y `spans`.
    - Se integra autom√°ticamente con librer√≠as populares de `Spring Boot` (`WebMVC`, `RestTemplate`, `WebClient`,
      `JdbcTemplate`, etc.).
    - Permite instrumentaci√≥n manual para crear `spans` personalizados.


2. `Bridge`
    - Conecta la abstracci√≥n de `Micrometer` con la implementaci√≥n de `OpenTelemetry`.
    - Sin este bridge, Micrometer no sabr√≠a c√≥mo crear traces reales.
    - Es el traductor entre las APIs de Micrometer y OpenTelemetry.


3. `OpenTelemetry (OTel)`
    - Es el est√°ndar abierto m√°s adoptado para trazabilidad.
    - Define c√≥mo representar `traces`, `spans`, `traceId`, `spanId`, etc.
    - Define protocolos de exportaci√≥n como `OTLP` `(OpenTelemetry Protocol)`.


4. `Exporter (OTLP)`
    - `OTLP` = OpenTelemetry Protocol.
    - Es el formato de comunicaci√≥n est√°ndar para enviar traces.
    - Este exporter convierte los traces internos de Java a formato OTLP.
    - Es el puente que env√≠a los traces desde tu aplicaci√≥n hacia un backend como `Tempo`.
    - Puede exportar v√≠a `gRPC (4317)` o `HTTP (4318)`.

üëâ En conjunto, el flujo completo de la trazabilidad es:

````
Spring Boot App 
   ‚îÇ  (Micrometer Tracing genera spans)
   ‚ñº
OpenTelemetry 
   ‚îÇ  (formatea y estandariza los datos de trace)
   ‚ñº
OTLP Protocol 
   ‚îÇ  (canal de exportaci√≥n gRPC/HTTP)
   ‚ñº
Tempo 
   ‚îÇ  (almacena y organiza los traces)
   ‚ñº
Grafana 
   ‚îÇ  (visualizaci√≥n y an√°lisis)
````

üéØ Beneficio pr√°ctico del flujo

- Cada `request` que entra a tu aplicaci√≥n queda representado como un `trace`.
- Cada operaci√≥n interna queda representada como un `span`.
- Los `traceId` permiten seguir el recorrido de un `request` de principio a fin.
- Al centralizar los datos en `Tempo + Grafana`, puedes:
    - Visualizar la l√≠nea de tiempo de un request.
    - Detectar cuellos de botella o partes lentas en el flujo.
    - Correlacionar `logs ‚Üî m√©tricas ‚Üî traces` para un diagn√≥stico m√°s r√°pido.

### ‚öôÔ∏è Dependencias a agregar

En el `pom.xml` incluimos las siguientes dependencias para habilitar trazabilidad con `Micrometer Tracing` y
exportaci√≥n a `Tempo`.

````xml

<dependencies>
    <!-- Micrometer Tracing Bridge -->
    <dependency>
        <groupId>io.micrometer</groupId>
        <artifactId>micrometer-tracing-bridge-otel</artifactId>
    </dependency>
    <!-- OpenTelemetry Exporter (para OTLP ‚Üí Tempo) -->
    <dependency>
        <groupId>io.opentelemetry</groupId>
        <artifactId>opentelemetry-exporter-otlp</artifactId>
    </dependency>
    <!-- Enriquece los logs con el contexto del traceId y spanId -->
    <dependency>
        <groupId>io.micrometer</groupId>
        <artifactId>micrometer-observation</artifactId>
    </dependency>
</dependencies>
````

- `micrometer-tracing-bridge-otel` es la base de la instrumentaci√≥n. Act√∫a como puente entre la API de observaci√≥n de
  `Micrometer (Observation)` y el tracer de `OpenTelemetry`. Gracias a esta dependencia, `Spring Boot` puede generar
  `spans` autom√°ticamente en controladores, clientes HTTP, tareas as√≠ncronas, etc., sin necesidad de instrumentaci√≥n
  manual. Adem√°s, permite desacoplar el c√≥digo de negocio de la API nativa de `OpenTelemetry`, manteniendo una
  arquitectura limpia y portable.


- `opentelemetry-exporter-otlp` env√≠a los traces generados por `Micrometer` hacia `Tempo` usando el protocolo est√°ndar
  `OTLP (gRPC/HTTP)`. Esta dependencia se encarga exclusivamente de la `exportaci√≥n`: no genera spans ni los modifica,
  solo los transmite al backend configurado. Requiere definir propiedades como `otel.traces.exporter=otlp` y
  `otel.exporter.otlp.endpoint=http://tempo:4318` para funcionar correctamente. Tambi√©n puede usarse con otros backends
  compatibles con OTLP como Jaeger, Honeycomb o Grafana Cloud.


- `micrometer-observation` integra el contexto de tracing en los logs y m√©tricas. Gracias a esta dependencia, cada log
  queda enriquecido autom√°ticamente con `traceId` y `spanId`, permitiendo correlacionar `logs ‚Üî traces ‚Üî m√©tricas`.
  `Spring Boot` lo hace mediante `MDC (Mapped Diagnostic Context)`, lo que permite que los logs estructurados en JSON
  incluyan los identificadores de trazas sin necesidad de configuraci√≥n adicional. Tambi√©n habilita la captura de
  m√©tricas observadas como duraci√≥n de spans, errores, etc.

### ‚öôÔ∏è Configuraci√≥n de tracing en el `application.yml`

Agregamos la configuraci√≥n de tracing en nuestro `application.yml` para habilitar el env√≠o de trazas distribuidas
desde `Spring Boot` hacia `Tempo` utilizando el protocolo `OTLP HTTP`.

````yml
management:
  tracing:
    sampling:
      probability: 1.0  # Captura el 100% de trazas (en prod suele usarse 0.1 o 0.01)
  otlp:
    tracing:
      endpoint: http://localhost:4318/v1/traces  # OTLP HTTP (Tempo)
````

- `tracing`, activa el soporte de trazas dentro de Spring Boot. Esta clave habilita el sistema de observaci√≥n basado en
  `Micrometer Tracing`.
- `sampling`, define c√≥mo se comporta el muestreo de trazas, es decir, qu√© porcentaje de peticiones ser√°n trazadas.
- `probability: 1.0`, establece la probabilidad de muestreo en 100%. Esto significa que todas las peticiones ser√°n
  trazadas. En entornos de producci√≥n se recomienda reducir este valor para evitar sobrecarga.
- `otlp`, indica que se usar√° el protocolo `OTLP (OpenTelemetry Protocol)` para exportar las trazas. Spring Boot lo
  utiliza internamente para enviar los spans generados.
- `tracing`, especifica la configuraci√≥n particular para el env√≠o de trazas bajo el protocolo OTLP.
- `endpoint: http://localhost:4318/v1/traces`, define la URL del receptor OTLP HTTP. En este caso, apunta al servicio
  de `Tempo` corriendo en el puerto `4318`, que es el receptor HTTP por defecto. Esta URL es donde se enviar√°n los spans
  generados por la aplicaci√≥n.

### Configurando `custom-layout.json` con contexto de trazas

`Micrometer Tracing` propaga el contexto de trazas (`traceId`, `spanId`) a trav√©s de `MDC (Mapped Diagnostic Context)`.
Esto significa:

- Los valores est√°n disponibles autom√°ticamente en el contexto del hilo.
- No se imprimen en los logs autom√°ticamente ‚Äî eso depende del layout.

Como estamos usando `Log4j2` con layout `JSON`, debemos definir manualmente los campos `traceId` y `spanId` en nuestro
`custom-layout.json` para que se incluyan en cada l√≠nea de `log`:

````json
{
  "timestamp": {
    "$resolver": "timestamp",
    "pattern": "yyyy-MM-dd'T'HH:mm:ss.SSSZ"
  },
  "level": {
    "$resolver": "level",
    "field": "name"
  },
  "thread": {
    "$resolver": "thread",
    "field": "name"
  },
  "logger": {
    "$resolver": "logger",
    "field": "name"
  },
  "message": {
    "$resolver": "message",
    "stringified": false
  },
  "exception": {
    "$resolver": "exception",
    "field": "stackTrace",
    "stackTrace": {
      "stringified": true
    }
  },
  "traceId": {
    "$resolver": "mdc",
    "key": "traceId"
  },
  "spanId": {
    "$resolver": "mdc",
    "key": "spanId"
  }
}
````

- `$resolver`: indica el origen del dato que se va a incluir en el log. En este caso, `mdc` significa que el valor se
  obtiene del `MDC (Mapped Diagnostic Context)`.
- `key`: es la clave dentro del `MDC` que queremos extraer. `Micrometer Tracing` ya coloca autom√°ticamente `traceId` y
  `spanId` en el `MDC` durante cada petici√≥n.

Una vez hecho esto, `Micrometer` se encarga de poblar esos valores en cada petici√≥n, sin necesidad de escribir c√≥digo
adicional. As√≠, cada l√≠nea de log queda enriquecida con el identificador de traza y el identificador del span actual,
lo que permite correlacionar f√°cilmente los logs con las trazas en `Tempo` o `Grafana`.

